---
title: "Eindopdracht"
author: "Mohammed Al Hor"
date: "2022-12-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
```{r}
#libs
library(dplyr)
library(readr)
library(ggplot2)
library(gridExtra)
library(lmtest)
library(moments)
library(tseries)
library(stringr)
library(forecast)
```

## Deelvraag 1,2 
Deze zeer relevante dataset bevat de dagelijkse personeelsverliezen aan Russische kant van de oorlog in Ukraine. In dit rapport gaan we kijken naar EDA (Exploratory Data Analysis) doen en daarna een stukje forecasting proberen te doen op deze data. Verschillende visualisaties en modellen zullen aan bod komen. Deze modellen gaan we met elkaar vergelijken om uiteindelijk het beste model uit te kiezen en deze te gebruiken om voorspellingen te doen.
Inladen van de data:
```{r}
setwd("~/Data-Science-Business-Analytics")
russia_losses_personnel <- read_csv("Data/russia_losses_personnel.csv")
```


Onderstaand figuur geeft ons een eerste blik op de data. Omdat we het hier hebben over cummulatieve personeelsverlizen zien we uitereaard een stijgende lijn in dit aantal. 
```{r}
plot1 <- ggplot(russia_losses_personnel, aes(x=date, y=personnel)) +geom_line() + labs(title = "Cummulatieve dagelijkse personeelsverliezen")
```


De eerste verschillen (first differences) worden berekend, zodat we deze kunnen visualizeren.
```{r}
russia_losses_personnel <- russia_losses_personnel %>% mutate(diff = personnel - lag(personnel))
```

Cummulatieve en dagelijkse/incrementel personeelsverliezen onder elkaar.
```{r}
require(gridExtra)
plot2 <- ggplot(russia_losses_personnel, aes(x=date, y=diff)) +geom_point() + geom_smooth() + labs(title = "Incrementele dagelijkse personeelsverliezen")
grid.arrange(plot1, plot2, ncol=1)
```
We observeren een aanzienlijke variantie wat betreft personeelsverliezen in de eerste dagen van de oorlog. Een verklaring voor deze variantie is het feit dat er in de eerste dagen de personeelsverliezen niet dagelijks werden geupdated. We zien voor sommige dagen nul personeelsverliezen die in de opvolgende dagen worden overgecompenseerd. 

Laten we de dataset opdelen in een training en test set, zodat het echte werk kan beginnen.
```{r}
estimation_sample <- russia_losses_personnel %>% filter(date <= '2022-10-03')
test_sample <- russia_losses_personnel %>% filter(date > '2022-10-03')
```


We berkenen de (partitiele) autocorrelaties voor de cummulatieve personeelsverliezen:
```{r}
max_lag <- 15
acf_pacf <- tibble(lag = 1:max_lag,
                   acf = acf(estimation_sample$personnel, max_lag)$acf[2:(max_lag + 1)],
                   pacf = pacf(estimation_sample$personnel, max_lag)$acf)
```
We zien dat alle momenten significant zijn, wat typerend is voor niet stationaire data. We zouden nog een ADF (Augmented Dickey Fueller) test kunnen doen om dit te bevestigen.
```{r}
adf.test(estimation_sample$personnel)
```
Hoge p-waarde maakt het dat we de null hypothese niet kunnen verwerpen (personeelsverliezen zijn dus niet stationair)
## Deelvraag 3
We gaan verder met de verschillen. Omdat het aantal personeelsverliezen cummulatief is, en dus alleen maar zal groeien, is het handig om te kijken naar de groei of de verschillen in personeelsverliezen. Dit process heet 'detrending' of 'differencing' en wordt toegpast als er een duidelijke trend in de data zit. Deze hebben we in vorige vraag al berekend.
## Deelvraag 4
Laten we nu gaan kijken naar de (partitiele) autocorrelaties voor incrementele/dagelijkse personeelsverliezen

```{r}
estimation_sample$diff[is.na(estimation_sample$diff)] <- 0 
acf_pacf <- tibble(lag = 1:max_lag,
                   acf = acf(estimation_sample$diff, max_lag)$acf[2:(max_lag + 1)],
                   pacf = pacf(estimation_sample$diff, max_lag)$acf)
```



## Deelvraag 5
Voordat we met het leuke werk gaan beginnen moeten we we eerst een check doen of onze data stationair is. Wat inhoudt dat de mean en de variantie constant moeten zijnn en er geen seizoenseffecten in mogen zitten. Hiervoor gebruiken we de ADF, ofwel Augmented Dickey Fueller test.

```{r}
adf.test(estimation_sample$diff)
```

P-waarde is kleiner dan 0.05, we kunnen de null hypothese verwerpen en aannemen dat de data stationair is.


Omdat er geen 'cut off' point zit in beide grafieken kunnen we geen definitieve keuze maken tussen een AR of MA model. Ons eerste model wordt dus een ARMA model. De parameters voor dit model gaan we schatten door middel van het 'forecast' package. De auto.arima functie in dit package geeft het beste model terug op basis van AIC. 

```{r}
stepwise_fit <- auto.arima(estimation_sample$diff, stationary = TRUE)
summary(stepwise_fit)
arma_1 <- arima(estimation_sample$diff, c(3,0,3))
summary(arma_1)
```
Het beste model (laagste AIC) is een ARIMA(3,0,3) model. Laten we hierop wat diagnostische testen doen:
```{r}
lb_test_result <- Box.test(actuals_predict$residual, lag = 1, type = c("Ljung-Box"), fitdf = 0)
```
```{r}
ar <- lm(diff ~ lag(diff, 1) + lag(diff, 2) + lag(diff, 3) , data = estimation_sample)
summary(ar)
```





PACF is used to evaluate AR model

ar <- lm(diff ~ lag(diff, 2) + lag(diff, 3) + lag(diff, 5) + lag(diff, 12) , data = estimation_sample)
summary(ar)



## Deelvraag 6






